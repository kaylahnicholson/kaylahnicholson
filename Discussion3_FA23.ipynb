{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxU6oSJx7639"
   },
   "source": [
    "# INFO 2950 Discussion Week 3\n",
    "\n",
    "For our group time on Friday we will be going through a tutorial on web scraping together.\n",
    "\n",
    "**Make sure to complete and save this notebook before next Friday's section!** We will use the completed version for an activity on pushing to GitHub next week.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-34StO4VWhP6"
   },
   "source": [
    "## What is web scraping?\n",
    "\n",
    "Web scraping is the process of creating structured data frames readable by computers from less-structured web pages that are intended to be read by humans.\n",
    "\n",
    "## Do you need to scrape?\n",
    "\n",
    "Scraping is difficult, error-prone, and may get you in legal or ethical trouble. Always check if the information you are seeking already exists in a nicer format. Many companies also have APIs or other infrastructure dedicated to serving automated requests.\n",
    "\n",
    "## Ethics of scraping\n",
    "\n",
    "Scraping is the aspect of data science most likely to get you into trouble. Legally, there are two main concerns: copyright violation if you are making copies of content that is protected by copyright, and terms-of-service violation. Many sites will also attempt to block scrapers. Acting to avoid these blocks may constitute hacking.\n",
    "\n",
    "In addition to legal problems, there are ethical problems.\n",
    "\n",
    "* Respect other people's hard work. Collecting information for a cool website is difficult and takes a long time and careful preparation. Is it fair to take all that work and use it for your purposes?\n",
    "* Respect other people's businesses. People feed their families by collecting and sharing information, for example through ad revenue. They may be unhappy if they think you are trying to steal their work and prevent them from monetizing it. Websites also sometimes pay for bandwidth and cloud services, and you don't want to take up all their resources for purposes that provide no revenue.\n",
    "* Respect other people's audiences. Don't [DDOS](https://en.wikipedia.org/wiki/Denial-of-service_attack) a website! Keep requests spaced to about 2/second at most. Web hits don't take a lot of resources, but it's easy to flood a site with requests, locking others out.\n",
    "\n",
    "## Process\n",
    "\n",
    "Find a page that contains the info you want. Some older pages are static, but most of what you will see today are views of databases. For example, Amazon has a database of products, Letterboxd has a database of movies, and Netflix has a database of shows. Each page either lists entities in the database or gives information about specific entities.\n",
    "\n",
    "You would prefer to get access directly to the database, and in some cases you can. But for whatever reason sometimes the web page is all you can get. This process can be difficult because web pages are optimized for people to look at, not for computers to operate on. But it is simpler because in this case a computer has to generate a page *from* a database record and a web browser has to know how to display the elements on the page so that humans can read them. These constraints mean that there are regularities in how specific pieces of information are shown in  HTML, and if you can figure them out, you can reverse the page generation process and get back to something that looks more like a database.\n",
    "\n",
    "How do you know which pages to get? Often an index or search result page leads to individual pages with more detailed information.\n",
    "\n",
    "\n",
    "### Web scraping in Python\n",
    "\n",
    "The [`requests`](https://requests.readthedocs.io/en/latest/) library allows you to download files from the web. It is much easier to use than `urllib`. You can use the `requests` library to get information from web pages so that you can save them to files or analyze their data in python.\n",
    "\n",
    "After using `requests` to access web data, you'll use [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to parse that information, organized in HTML. `BeautifulSoup` makes querying a tree of tags and their attributes much easier than trying to parse HTML from scratch. You'll need to spend some time looking at the target web page and finding the combination of tag names and classes you're interested in, but `BeautifulSoup` can help access that information once you know what you need.\n",
    "\n",
    "\n",
    "\n",
    "## Installation\n",
    "As usual, to use these new modules you'll need to first **install `BeautifulSoup` and `requests` to your virtual environment for this class**. Only once you've completed that process can successfully you run the next cell of code to load in `requests`, `BeautifulSoup`, and other modules.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KIQy8gAoHZ9_"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FlYjVsZA3j__"
   },
   "source": [
    "## In-session Example: Cornell University Website\n",
    "\n",
    "The TA will show you [this page about Cornell University](https://www.cornell.edu/about/). This webpage has information about Cornell, including general statistics about number of students, different campus locations, and many links to other Cornell pages.\n",
    "\n",
    "## Viewing HTML\n",
    "Take a look at the HTML of the page. You can view this in a couple of different ways:\n",
    "\n",
    "*   Right click > \"View Page Source\"\n",
    "*   Right click > \"Inspect\"\n",
    "\n",
    "**What differences do you notice between the two HTML views?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyAS5Km3KgYI"
   },
   "source": [
    "Today, our goal is to collect and organize various stats about Cornell.\n",
    "\n",
    "We need to put together clues from the structure of the page and the appearance of elements on the page. Appearance is usually determined by the CSS `style` property. Figuring out how to automatically find values from HTML will involve looking at HTML source, ^F searching for values that you want, and figuring out how to identify styles or containing elements. Modern web pages are long and have lots of complicated elements, many of which do not appear as visible content. Starting from the top of the document and reading through is not recommended.\n",
    "\n",
    "You will scrape information from cached copies of \"About Cornell\" pages. These are locally hosted so we don't have hundreds of students hitting Cornell's website at the same time. They probably wouldn't notice, but it's more responsible to keep it local.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EBJxOwcm1Og2"
   },
   "outputs": [],
   "source": [
    "cornell_url = \"https://koenecke.infosci.cornell.edu/files/info2950/About%20Cornell%20University.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVga8D7A8nHc"
   },
   "source": [
    "The following code does a `GET` request to the web host for the specified filename. HTTP is the protocol used to make web requests. It has a series of \"status codes\" that tell you the result of request. 200 is success. Others you have probably seen: 404 is \"page not found\", 403 is \"you do not have access\". Codes starting with 3-- are often redirects. 500 means there is a bug in the server-side code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "iKMoioQN1PrE"
   },
   "outputs": [],
   "source": [
    "cornell_result = requests.get(cornell_url)\n",
    "if cornell_result.status_code != 200:\n",
    "  print(\"something went wrong:\", cornell_result.status_code, cornell_result.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7toLvE68qF5"
   },
   "source": [
    "You're never going to get the analysis of a web page right the first time, so it's good to save a local copy of the HTML source so we don't need to hit the server again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "T--49WBb1Vch"
   },
   "outputs": [],
   "source": [
    "with open(\"cornell_about.html\", \"w\") as writer:\n",
    "  writer.write(cornell_result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYSfu-898tcc"
   },
   "source": [
    "Here we're immediately reading the file again, but you could split these into two separate notebooks, one for downloading, one for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OsuOFDfB1Zxc"
   },
   "outputs": [],
   "source": [
    "with open(\"cornell_about.html\", \"r\") as reader:\n",
    "  html_source = reader.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCQTpxKf8xbQ"
   },
   "source": [
    "There are a lot of things that can go wrong when you are accessing web documents. Get in the habit of constantly adding confidence checks to make sure the state of variables is what you expect it to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "K3a1nh1p1gGy",
    "outputId": "4938fb12-e7e4-4c56-c326-fe499b4c0407"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<htm'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure this worked\n",
    "html_source[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8e0HyLsI80rh"
   },
   "source": [
    "Here's where we turn the HTML text from a single long string into a searchable tree of tags. `BeautifulSoup` can support different ways of parsing (including XML). Here we'll use an HTML parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dG_c_myU1h-7"
   },
   "outputs": [],
   "source": [
    "page = BeautifulSoup(html_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t12d_OJf9Iq4"
   },
   "source": [
    "Now that we have a structured document we can ask for specific tags. See the Beautiful Soup documentation linked at the top for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FD9w7WBE1j4X",
    "outputId": "5f5eee2a-8ef3-4f67-dbf9-95ac6dd360a6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>About | Cornell University</title>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SRj_xxyv_fRp"
   },
   "source": [
    "If you want just the text between the HTML tags, you can use `.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pQdpwDP5_cAU",
    "outputId": "5f96554e-db26-43c5-da15-eb577ff3a14c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About | Cornell University'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPYxP0Cw9A9g"
   },
   "source": [
    "We can also find all of the instances of a given tag. Since this \"About Cornell\" page seems like more of a landing page, pointing to other resources, we want to use the links on this page to get us to that other linked information. What happens if we ask for all the `a` tags, which [defines a hyperlink](https://www.w3schools.com/tags/tag_a.asp)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TxUmldHs1mA2",
    "outputId": "12e08e96-ae4b-42a8-94ac-3cbdca8d9d42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 180 links on the page\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://www.cornell.edu/about/\">https://www.cornell.edu/about/</a>,\n",
       " <a href=\"https://www.cornell.edu/about/\">current page</a>,\n",
       " <a href=\"http://support.google.com/websearch/bin/answer.py?hl=en&amp;p=cached&amp;answer=1687222\"><span>Learn more</span>.</a>,\n",
       " <a href=\"http://webcache.googleusercontent.com/search?q=cache:FwQY78IHD64J:https://www.cornell.edu/about/&amp;sca_esv=562865996&amp;hl=en&amp;gl=us&amp;strip=1&amp;vwsrc=0\"><span>Text-only version</span></a>,\n",
       " <a href=\"http://webcache.googleusercontent.com/search?q=cache:FwQY78IHD64J:https://www.cornell.edu/about/&amp;sca_esv=562865996&amp;hl=en&amp;gl=us&amp;strip=0&amp;vwsrc=1\"><span>View source</span></a>,\n",
       " <a data-click-action=\"skip to content\" data-click-category=\"header\" href=\"#main\" tabindex=\"1\">Skip to content</a>,\n",
       " <a data-click-action=\"home\" data-click-category=\"header\" href=\"https://www.cornell.edu/\" id=\"cu-brand\" title=\"Cornell.edu Homepage\">\n",
       " <div class=\"cu-logotype\">Cornell University</div>\n",
       " </a>,\n",
       " <a class=\"menu-item\" data-click-label=\"About Cornell\" href=\"https://www.cornell.edu/about\">About Cornell</a>,\n",
       " <a aria-expanded=\"false\" aria-label=\"toggle the About Cornell sub-menu\" class=\"submenu-trigger\" data-click-label=\"About Cornell\" href=\"https://www.cornell.edu/about\"><span class=\"off-screen\">About Cornell</span></a>,\n",
       " <a data-click-label=\"Overview\" href=\"https://www.cornell.edu/about/\">\n",
       " <img alt=\"blue sky over the Arts Quad\" aria-hidden=\"true\" class=\"image-replace\" data-src=\"https://www.cornell.edu/assets/core/images/nav-overview-about.jpg\" src=\"About%20Cornell%20University_files/nav-overview-about.jpg\"/>\n",
       " <span>Overview</span>\n",
       " </a>,\n",
       " <a data-click-label=\"Cornell History\" href=\"https://www.cornell.edu/about/timeline/\">Cornell History</a>,\n",
       " <a data-click-label=\"Maps &amp; Directions\" href=\"https://www.cornell.edu/about/maps/\">Maps &amp; Directions</a>,\n",
       " <a data-click-label=\"Mission\" href=\"https://www.cornell.edu/about/mission.cfm\">Mission &amp; Vision</a>,\n",
       " <a data-click-label=\"Values\" href=\"https://www.cornell.edu/about/values.cfm\">Core Values</a>,\n",
       " <a data-click-label=\"Locations\" href=\"https://www.cornell.edu/about/locations/\">Locations</a>,\n",
       " <a data-click-label=\"Ithaca\" href=\"https://www.cornell.edu/about/locations/ithaca/\">Ithaca</a>,\n",
       " <a data-click-label=\"New York City\" href=\"https://www.cornell.edu/about/locations/nyc/\">New York City</a>,\n",
       " <a aria-label=\"Diversity at Cornell\" data-click-label=\"Diversity\" href=\"https://diversity.cornell.edu/\">Diversity</a>,\n",
       " <a aria-label=\"Indigenous Engagement: Commitment to North American Indigenous Nations and Communities\" data-click-label=\"Indigenous\" href=\"https://indigenous.cornell.edu/\">Indigenous Engagement</a>,\n",
       " <a data-click-label=\"Economic Impact\" href=\"https://economicimpact.cornell.edu/\">Economic Impact</a>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = page.find_all(\"a\")\n",
    "print(\"there are\", len(links), \"links on the page\")\n",
    "links[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZBQzVbH9M9P"
   },
   "source": [
    "Whoa, that's too much! And most of these links seem to be navigation links in header menus.\n",
    "\n",
    "Let's be more specific. Viewing the source, we can search for an interesting string (like \"Facts about Cornell\") and look at the HTML around it.\n",
    "\n",
    "Inspecting the HTML we find that `a` tags can be associated with a number of class styles. The class style for \"Facts about Cornell\" is `link-caret`. Here's how to find all of the `a` tags with this style:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NcYr_2f1t4L",
    "outputId": "785e3bd0-f7a9-4b9f-8c43-587205216860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a class=\"link-caret\" href=\"https://www.cornell.edu/about/locations.cfm\" title=\"Cornell around the globe\">\n",
      "  See All Locations\n",
      "</a>, <a class=\"link-caret\" href=\"https://irp.dpb.cornell.edu/university-factbook\" title=\"Facts about Cornell\">\n",
      "  See All University Facts\n",
      "</a>, <a class=\"link-caret\" href=\"https://www.cornell.edu/about/timeline/\" title=\"Cornell's Historical Timeline\">\n",
      "  Explore Cornell's History\n",
      "</a>]\n"
     ]
    }
   ],
   "source": [
    "link_carets = page.find_all(\"a\", {\"class\":\"link-caret\"})\n",
    "print(link_carets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yWoAxkMF91Dk"
   },
   "source": [
    "Once we find a tag, we can also access attributes of the tag, like the URL target of a link (`href`) or the text contained within the tag (`.text`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGqZLu4F1v0R",
    "outputId": "402e05f5-f2aa-43ad-bdb0-f3c7efd5b0a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  See All Locations\n",
      " https://www.cornell.edu/about/locations.cfm\n",
      "\n",
      "  See All University Facts\n",
      " https://irp.dpb.cornell.edu/university-factbook\n",
      "\n",
      "  Explore Cornell's History\n",
      " https://www.cornell.edu/about/timeline/\n"
     ]
    }
   ],
   "source": [
    "for link in link_carets:\n",
    "  print(link.text, link[\"href\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9diPMwaL9390"
   },
   "source": [
    "## Organizing structured data\n",
    "Now, we want to collect different stats and facts about Cornell, so the table on the right side with \"Quick Facts\" seems like a great place to start. **Our goal is to recreate the \"Quick Facts\" table as a pandas dataframe.**\n",
    "\n",
    "Remember, instead of reading the HTML from start to bottom, use ^F to search for the text \"Undergraduate Students\" (for example).\n",
    "\n",
    "While there are different ways of collecting this tag, you really want to keep the name of the fact and its value together. For this reason, let's collect the list element as a singular unit (with tag `li` and the `stat` class style)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6wlMDuE1z7D",
    "outputId": "c78299eb-6343-4d94-fea6-78f04bdd48d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "cornell_stats = page.find_all(\"li\", {\"class\": \"stat\"})\n",
    "print(len(cornell_stats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxFI-81hDCNR"
   },
   "source": [
    "Now that we have a list of every `li` (list item) with the `stat` class, we can extract the values of the list. Let's start with the first item in this new list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuUevyy8DbJO",
    "outputId": "71c8483d-43b5-4e25-9aa7-5aecaff81af4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Undergraduate Students\n",
      "      \n",
      "\n",
      "         15,735\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "print(cornell_stats[0].find(\"div\", {\"class\": \"stat-label\"}).text)\n",
    "print(cornell_stats[0].find(\"div\", {\"class\": \"stat-value\"}).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUI58jBkDfjG"
   },
   "source": [
    "What's with all that whitespace? You can strip the extra whitespace with `.strip()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoyR2jGH2RF7",
    "outputId": "53cfe85d-b306-4126-ca8a-ed4c8543a919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undergraduate Students\n",
      "15,735\n"
     ]
    }
   ],
   "source": [
    "print(cornell_stats[0].find(\"div\", {\"class\": \"stat-label\"}).text.strip())\n",
    "print(cornell_stats[0].find(\"div\", {\"class\": \"stat-value\"}).text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWlLu9ebDOOI"
   },
   "source": [
    "Much better! Now, we can use a loop to extract the label and value from each list item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYbgOxdW13CQ",
    "outputId": "109fc2f5-37ae-4e58-932f-1f71052562b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undergraduate Students\n",
      "15,735\n",
      "Graduate Students\n",
      "10,163\n",
      "Faculty\n",
      "2,864\n",
      "Nobel Laureates\n",
      "50\n",
      "Colleges and Schools\n",
      "17\n",
      "undergraduate grant aid (FY23)\n",
      "$407M\n"
     ]
    }
   ],
   "source": [
    "for html_stat in cornell_stats:\n",
    "  print(html_stat.find(\"div\", {\"class\": \"stat-label\"}).text.strip())\n",
    "  print(html_stat.find(\"div\", {\"class\": \"stat-value\"}).text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYfFnvBxDs6e"
   },
   "source": [
    "In reality, you probably don't just want to print these items. You want to store them! Let's use **list comprehension** to create two lists, `labels_l` and `value_l`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "T0S-y8Oa2jRw"
   },
   "outputs": [],
   "source": [
    "label_l = [stat.find(\"div\", {\"class\": \"stat-label\"}).text.strip() for stat in cornell_stats]\n",
    "value_l = [stat.find(\"div\", {\"class\": \"stat-value\"}).text.strip() for stat in cornell_stats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20B42tLXD30j"
   },
   "source": [
    "Now, we can store this as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Sui4GiCs2z-w"
   },
   "outputs": [],
   "source": [
    "data = {'Label':label_l, 'Stat':value_l}\n",
    "cornell_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "4Z1m6LCn29aH",
    "outputId": "86f84b6d-c0c7-4251-be12-3be1745c070e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Stat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Undergraduate Students</td>\n",
       "      <td>15,735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Graduate Students</td>\n",
       "      <td>10,163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Faculty</td>\n",
       "      <td>2,864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nobel Laureates</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Colleges and Schools</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>undergraduate grant aid (FY23)</td>\n",
       "      <td>$407M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Label    Stat\n",
       "0          Undergraduate Students  15,735\n",
       "1               Graduate Students  10,163\n",
       "2                         Faculty   2,864\n",
       "3                 Nobel Laureates      50\n",
       "4            Colleges and Schools      17\n",
       "5  undergraduate grant aid (FY23)   $407M"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cornell_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is there any other data cleaning you'd do to this dataframe if you wanted to use it for data science?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvZdPQnG2yZp"
   },
   "source": [
    "## Collecting text\n",
    "Often, when you're scraping a website you aren't just collecting headers and tables. You're also collecting text! Now, you're going to collect the text below \"Our Profile.\" Use ^F to find the first sentence in the HTML.\n",
    "\n",
    "You should find that the text is in a `p` tag below a `div` tag. **What class would you use to extract this `div` tag?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VdPJcRtD15vH",
    "outputId": "92699824-00ed-438c-fb79-017de4c6c3e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"about-block about-profile\">\n",
      "<h3 class=\"cu-title\">\n",
      "    Our Profile\n",
      "  </h3>\n",
      "<p>Cornell is a privately endowed research university and a partner of\n",
      " the State University of New York. As the federal land-grant institution\n",
      " in New York State, we have a responsibility—unique within the Ivy \n",
      "League—to make contributions in all fields of knowledge in a manner that\n",
      " prioritizes public engagement to help improve the quality of life in \n",
      "our state, the nation, the world.</p>\n",
      "<!-- <ul class=\"link-list\">\n",
      "          <li>\n",
      "            <a href=\"/engagement/\" title=\"Public Engagement\">\n",
      "             Public Engagement\n",
      "            </a>\n",
      "          </li>\n",
      "          <li>\n",
      "            <a href=\"http://irp.dpb.cornell.edu/university-factbook\" title=\"All the facts\">\n",
      "              University Factbook\n",
      "            </a>\n",
      "          </li>\n",
      "        </ul>-->\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "about_profile = page.find(\"div\", {\"class\":\"about-block about-profile\"}) # THIS CELL WILL NOT EXECUTE UNTIL YOU FILL IN THE CLASS\n",
    "print(about_profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsHlLrWVFcqF"
   },
   "source": [
    "Before moving on, **do you notice anything odd about the above HTML?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YKgFyKs-FOOi"
   },
   "source": [
    "Now, if we want to extract the natural text from the `about_profile` variable, we can use the `p` tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "Run7tprF17Vw",
    "outputId": "b48902dd-882f-4950-f2c2-ecf2777db3d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cornell is a privately endowed research university and a partner of\n",
      " the State University of New York. As the federal land-grant institution\n",
      " in New York State, we have a responsibility—unique within the Ivy \n",
      "League—to make contributions in all fields of knowledge in a manner that\n",
      " prioritizes public engagement to help improve the quality of life in \n",
      "our state, the nation, the world.\n"
     ]
    }
   ],
   "source": [
    "print(about_profile.find('p').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsY8lKVe3gEt"
   },
   "source": [
    "---\n",
    "# Problem 2: Recreating the timeline as a table\n",
    "\n",
    "Earlier, you found links to fact pages about Cornell (stored in `link_carets`). One of those links was to a Cornell Timeline (https://www.cornell.edu/about/timeline/). Take some time to inspect the HTML of the page, and then load the cached version with the link below, create a `BeautifulSoup` object, and find some information about Cornell.\n",
    "\n",
    "Notice the table of data **Cornell Through the Years** with information about Cornell's history. It looks like each event includes three types of information:\n",
    "\n",
    "1.   Event year\n",
    "2.   Event title\n",
    "3.   Event summary\n",
    "\n",
    "Use `BeautifulSoup` and `requests` to scrape this data and format it as a data frame with one column for the year, another for the title, and a third for the summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVaEkWjLW_6M"
   },
   "source": [
    "1. Use the requests library to `get` the website's HTML. Check the status code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZsGr_ZUI2WWG"
   },
   "outputs": [],
   "source": [
    "timeline_url = \"https://koenecke.infosci.cornell.edu/files/info2950/About%20Cornell%20University%20Timeline.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "EZV2RMBt3m_H"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "timeline_result = requests.get(timeline_url)\n",
    "if timeline_result.status_code != 200:\n",
    "  print(\"something went wrong:\", timeline_result.status_code, timeline_result.reason)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8LpCymIXNPA"
   },
   "source": [
    "2. Convert what you retrieved with the `requests` library to a text string.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OzFyt2vv4O0E"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "timeline_source = timeline_result.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTg5_CzZYma8"
   },
   "source": [
    "3. Parse the text as HTML with BeautifulSoup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Fuz27p9Q31IJ"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "page_t = BeautifulSoup(timeline_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZwSAn-x7Yr-w"
   },
   "source": [
    "4. Identify the HTML tag and class above the year, title, and summary text. Find all occurences of this tag and save it to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XhiSmL9h4LIS",
    "outputId": "4c12f113-dacd-4706-8302-323750bfc09d"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "timeline_events = page_t.find_all(\"div\", {\"class\": \"item-content\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fv7qPVzZY9RT"
   },
   "source": [
    "5. Access the year, title, and summary text at the 10th index position. Print these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uTGUOlmS4sua",
    "outputId": "1ecf1049-3669-4dc7-9407-4a2f2f471775"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1880\n",
      "\n",
      "Preston is first female doctoral graduate\n",
      "\n",
      "\n",
      "American educator and suffragist May Preston Slosson\n",
      " Ph.D. 1880 becomes the first woman in the country to earn a Ph.D. in \n",
      "philosophy. She is also Cornell's first female doctoral graduate.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "print(timeline_events[9].find(\"div\",{\"class\": \"item-year\"}).text)\n",
    "print(timeline_events[9].find(\"div\",{\"class\": \"item-title\"}).text)\n",
    "print(timeline_events[9].find(\"div\",{\"class\": \"item-desc\"}).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WuBB_nwAZTlQ"
   },
   "source": [
    "6. Collect all years, titles, and summaries in the list of timeline events. Add each of these to a list (`year_l`, `title_l`, and `summary_l`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "a0J29HLt5AIs"
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "year_l = []\n",
    "title_l = []\n",
    "summary_l = []\n",
    "\n",
    "for event in timeline_events:\n",
    "    year_l.append(event.find(\"div\", {\"class\": \"item-year\"}).text)\n",
    "    title_l.append(event.find(\"div\", {\"class\": \"item-title\"}).text)\n",
    "    summary_l.append(event.find(\"div\", {\"class\": \"item-desc\"}).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QcYQwrDeZjtW"
   },
   "source": [
    "7. Convert these lists into data frame columns and display the data frame.\n",
    "\n",
    "*Note: you might notice a couple of cells in the first and last row have missing information. This is an issue with the cached version of the webpage. You do not need to fix this.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "BMauprEw5Po0"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# your code here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m:year_l, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m:title_l, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msummary\u001b[39m\u001b[38;5;124m'\u001b[39m:summary_l}\n\u001b[0;32m----> 4\u001b[0m timeline_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/info2950/lib/python3.11/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/envs/info2950/lib/python3.11/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/envs/info2950/lib/python3.11/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/envs/info2950/lib/python3.11/site-packages/pandas/core/internals/construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "data = {'year':year_l, 'title':title_l, 'summary':summary_l}\n",
    "\n",
    "timeline_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JRwxJzFTJqSE"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WTDJt8R6VEW"
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "Select a page from the web that contains some table element. Extract the table's information and put it into a pandas data frame. Make sure to display the table when you are finished.\n",
    "\n",
    "As a suggestion, you may use the [Wikipedia page for Cornell University](https://en.wikipedia.org/wiki/Cornell_University). The table on the right side of the page is a good option for scraping and displaying.\n",
    "\n",
    "Remember to use the following steps, as you did above:\n",
    "1. Use the requests library to `get` the website's HTML. Check the status code.\n",
    "2. Convert what you retrieved with the `requests` library to a text string.\n",
    "3. Parse the text as HTML with BeautifulSoup.\n",
    "4. Manually search the HTML (with ^F) for the text strings you want to collect. Identify the tags and classes associated with that text.\n",
    "5. Use combinations of `find` and `find_all` to retrieve the text you are interested in.\n",
    "6. Convert the text to a data frame. Display this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "3Wu8wB-Kz6IG"
   },
   "outputs": [],
   "source": [
    "wiki_url = \"https://koenecke.infosci.cornell.edu/files/info2950/Cornell%20University%20-%20Wikipedia.html\" # optional cached version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "txk4mCPYgwP0",
    "outputId": "cad62e74-7bc4-4037-804e-929c972cf120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m year_l \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m wiki_table:\n\u001b[0;32m---> 12\u001b[0m     college_l\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtbody\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     13\u001b[0m     year_l\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtd\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-align: center\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mtext)\n\u001b[1;32m     15\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcollege\u001b[39m\u001b[38;5;124m'\u001b[39m: college_l, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: year_l}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# your code here, add as many cells as you need\n",
    "wiki_result = requests.get(wiki_url)\n",
    "if wiki_result.status_code != 200:\n",
    "  print(\"something went wrong:\", wiki_result.status_code, wiki_result.reason)\n",
    "wiki_source = wiki_result.text\n",
    "page_w = BeautifulSoup(wiki_source, \"html.parser\")\n",
    "wiki_table =  page_w.find_all(\"table\", {\"class\": \"toccolours\"})\n",
    "\n",
    "print(len(wiki_table))\n",
    "college_l = []\n",
    "year_l = []\n",
    "for x in wiki_table:\n",
    "    college_l.append(x.find(\"tbody\", \"a\").text)\n",
    "    year_l.append(x.find(\"td\", {\"style\": \"text-align: center\"}).text)\n",
    "\n",
    "data = {'college': college_l, 'year': year_l}\n",
    "\n",
    "print(wiki_df = pd.DataFrame(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1empeX0fj7XQ"
   },
   "source": [
    "## Submission\n",
    "**Make sure to complete and save this notebook before next Friday's section.** We will practice pushing and pulling code from GitHub and we will ask you to push a completed version of this notebook to that repository."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
